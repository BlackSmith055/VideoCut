import gradio as gr
import re
import tempfile
import os
import subprocess
import json
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import base64
import io
import whisper
import torch
# from googletrans import Translator
import json

# --- Utility: æ—¶é—´æ ¼å¼è§£æ ---
def time_to_seconds(time_str: str) -> float:
    """
    å°†å¤šç§æ—¶é—´æ ¼å¼è½¬æ¢ä¸ºç§’ï¼ˆæµ®ç‚¹æ•°ï¼‰ã€‚
    æ”¯æŒæ ¼å¼ï¼š
    - MM:SS (åˆ†é’Ÿ:ç§’)
    - HH:MM:SS (å°æ—¶:åˆ†é’Ÿ:ç§’)
    - HH:MM:SS.ss (å°æ—¶:åˆ†é’Ÿ:ç§’.æ¯«ç§’)
    """
    # å»é™¤ç©ºç™½å­—ç¬¦
    time_str = time_str.strip()
    
    # å°è¯• MM:SS æ ¼å¼
    pattern1 = r"^(?P<m>\d+):(?P<s>\d+(?:\.\d{1,2})?)$"
    m = re.match(pattern1, time_str)
    if m:
        minutes = int(m.group('m'))
        seconds = float(m.group('s'))
        return minutes * 60 + seconds
    
    # å°è¯• HH:MM:SS æ ¼å¼
    pattern2 = r"^(?P<h>\d+):(?P<m>[0-5]\d):(?P<s>\d+(?:\.\d{1,2})?)$"
    m = re.match(pattern2, time_str)
    if m:
        hours = int(m.group('h'))
        minutes = int(m.group('m'))
        seconds = float(m.group('s'))
        return hours * 3600 + minutes * 60 + seconds
    
    raise ValueError(f"æ—¶é—´æ ¼å¼æ— æ•ˆ: {time_str}. è¯·ä½¿ç”¨ MM:SS æˆ– HH:MM:SS æ ¼å¼ã€‚")

def seconds_to_ffmpeg_time(seconds: float) -> str:
    """å°†ç§’æ•°è½¬æ¢ä¸º FFmpeg æ—¶é—´æ ¼å¼ (HH:MM:SS.ss)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = seconds % 60
    return f"{hours:02d}:{minutes:02d}:{secs:06.3f}"

def get_video_duration(input_path: str) -> float:
    """ä½¿ç”¨ FFmpeg è·å–è§†é¢‘æ—¶é•¿"""
    try:
        cmd = [
            'ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
            '-of', 'json', input_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        data = json.loads(result.stdout)
        return float(data['format']['duration'])
    except Exception as e:
        print(f"è·å–è§†é¢‘æ—¶é•¿å¤±è´¥: {e}")
        return 0

def get_video_info(input_path: str) -> dict:
    """è·å–è§†é¢‘ä¿¡æ¯ï¼ˆåˆ†è¾¨ç‡ã€å¸§ç‡ç­‰ï¼‰"""
    try:
        cmd = [
            'ffprobe', '-v', 'quiet', '-select_streams', 'v:0',
            '-show_entries', 'stream=width,height,r_frame_rate',
            '-of', 'json', input_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        data = json.loads(result.stdout)
        stream = data['streams'][0]
        
        # è§£æå¸§ç‡
        fps_parts = stream['r_frame_rate'].split('/')
        fps = float(fps_parts[0]) / float(fps_parts[1])
        
        return {
            'width': int(stream['width']),
            'height': int(stream['height']),
            'fps': fps
        }
    except Exception as e:
        print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        return {'width': 1920, 'height': 1080, 'fps': 30}



def extract_video_frame(video_path: str, time_seconds: float = 0) -> str:
    """ä»è§†é¢‘ä¸­æå–æŒ‡å®šæ—¶é—´çš„å¸§ä½œä¸ºé¢„è§ˆå›¾"""
    try:
        tmp_dir = tempfile.gettempdir()
        frame_path = os.path.join(tmp_dir, f"preview_frame_{int(time_seconds*100)}.jpg")
        
        cmd = [
            'ffmpeg', '-i', video_path,
            '-ss', str(time_seconds),
            '-vframes', '1',
            '-q:v', '2',
            '-y', frame_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0 and os.path.exists(frame_path):
            return frame_path
        return None
    except Exception as e:
        print(f"æå–é¢„è§ˆå¸§å¤±è´¥: {e}")
        return None

def create_crop_preview_image(video_path: str, aspect_ratio: str, crop_x: float, crop_y: float, crop_width: float, crop_height: float) -> str:
    """åˆ›å»ºå¸¦æœ‰è£åˆ‡æ¡†çš„é¢„è§ˆå›¾åƒ"""
    try:
        # æå–è§†é¢‘å¸§
        frame_path = extract_video_frame(video_path, 0)
        if not frame_path:
            return None
        
        # è¯»å–å›¾åƒ
        img = cv2.imread(frame_path)
        if img is None:
            return None
        
        height, width = img.shape[:2]
        
        # è®¡ç®—è£åˆ‡æ¡†çš„å®é™…åƒç´ ä½ç½®
        crop_x_pixels = int(crop_x * width)
        crop_y_pixels = int(crop_y * height)
        crop_w_pixels = int(crop_width * width)
        crop_h_pixels = int(crop_height * height)
        
        # ç¡®ä¿è£åˆ‡æ¡†åœ¨å›¾åƒèŒƒå›´å†…
        crop_x_pixels = max(0, min(crop_x_pixels, width - crop_w_pixels))
        crop_y_pixels = max(0, min(crop_y_pixels, height - crop_h_pixels))
        crop_w_pixels = min(crop_w_pixels, width - crop_x_pixels)
        crop_h_pixels = min(crop_h_pixels, height - crop_y_pixels)
        
        # ç»˜åˆ¶è£åˆ‡æ¡†
        cv2.rectangle(img, 
                     (crop_x_pixels, crop_y_pixels), 
                     (crop_x_pixels + crop_w_pixels, crop_y_pixels + crop_h_pixels), 
                     (0, 255, 0), 3)
        
        # æ·»åŠ æ¯”ä¾‹æ ‡ç­¾
        label = f"{aspect_ratio} è£åˆ‡æ¡†"
        cv2.putText(img, label, (crop_x_pixels, crop_y_pixels - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        # ä¿å­˜é¢„è§ˆå›¾åƒ
        preview_path = os.path.join(tempfile.gettempdir(), f"crop_preview_{aspect_ratio}.jpg")
        cv2.imwrite(preview_path, img)
        
        return preview_path
        
    except Exception as e:
        print(f"åˆ›å»ºè£åˆ‡é¢„è§ˆå¤±è´¥: {e}")
        return None

def calculate_crop_box(video_width: int, video_height: int, aspect_ratio: str, center_x: float = 0.5, center_y: float = 0.5, scale: float = 0.8) -> dict:
    """æ ¹æ®æ¯”ä¾‹å’Œç¼©æ”¾è®¡ç®—è£åˆ‡æ¡†"""
    if aspect_ratio == "3:4":
        target_ratio = 3/4
    elif aspect_ratio == "1:1":
        target_ratio = 1
    else:  # 9:16
        target_ratio = 9/16
    
    # è®¡ç®—æœ€å¤§å¯èƒ½çš„è£åˆ‡æ¡†å°ºå¯¸
    if target_ratio > video_width / video_height:
        # ä»¥å®½åº¦ä¸ºåŸºå‡†
        max_crop_width = video_width * scale
        max_crop_height = max_crop_width / target_ratio
    else:
        # ä»¥é«˜åº¦ä¸ºåŸºå‡†
        max_crop_height = video_height * scale
        max_crop_width = max_crop_height * target_ratio
    
    # è®¡ç®—ä¸­å¿ƒä½ç½®
    center_x_pixels = int(center_x * video_width)
    center_y_pixels = int(center_y * video_height)
    
    # è®¡ç®—è£åˆ‡æ¡†ä½ç½®
    crop_x = (center_x_pixels - max_crop_width / 2) / video_width
    crop_y = (center_y_pixels - max_crop_height / 2) / video_height
    crop_width = max_crop_width / video_width
    crop_height = max_crop_height / video_height
    
    # ç¡®ä¿è£åˆ‡æ¡†åœ¨è§†é¢‘èŒƒå›´å†…
    crop_x = max(0, min(crop_x, 1 - crop_width))
    crop_y = max(0, min(crop_y, 1 - crop_height))
    
    return {
        'x': crop_x,
        'y': crop_y,
        'width': crop_width,
        'height': crop_height
    }

# --- äººç‰©æ£€æµ‹å’Œè·Ÿè¸ª ---
class PersonTracker:
    def __init__(self):
        # ä½¿ç”¨ OpenCV çš„ HOG äººç‰©æ£€æµ‹å™¨
        self.hog = cv2.HOGDescriptor()
        self.hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
        self.tracked_positions = []
        self.tracker = None
        self.initial_bbox = None
    
    def detect_person(self, frame):
        """æ£€æµ‹ç”»é¢ä¸­çš„äººç‰©ä½ç½®"""
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # æ£€æµ‹äººç‰©
        boxes, weights = self.hog.detectMultiScale(
            gray, 
            winStride=(8, 8),
            padding=(4, 4),
            scale=1.05
        )
        
        if len(boxes) > 0:
            # é€‰æ‹©æœ€å¤§çš„äººç‰©æ¡†ï¼ˆé€šå¸¸æ˜¯æœ€ä¸»è¦çš„äººç‰©ï¼‰
            largest_box = max(boxes, key=lambda x: x[2] * x[3])
            x, y, w, h = largest_box
            
            bbox = {
                'x': x,
                'y': y,
                'width': w,
                'height': h,
                'center_x': x + w // 2,
                'center_y': y + h // 2
            }
            
            self.tracked_positions.append(bbox)
            return bbox
        
        return None
    
    def initialize_tracker(self, frame, bbox):
        """åˆå§‹åŒ–è·Ÿè¸ªå™¨ - ä½¿ç”¨åŸºäºæ£€æµ‹çš„è·Ÿè¸ªæ–¹æ³•"""
        self.initial_bbox = bbox
        self.last_bbox = bbox
        self.tracked_positions = [bbox]
        return True
    
    def track_person(self, frame):
        """è·Ÿè¸ªäººç‰©ä½ç½® - ä½¿ç”¨åŸºäºæ£€æµ‹çš„è·Ÿè¸ªæ–¹æ³•"""
        if self.initial_bbox is None:
            return None
        
        # åœ¨ä¸Šä¸€å¸§ä½ç½®é™„è¿‘æ£€æµ‹äººç‰©
        last_x, last_y, last_w, last_h = (
            self.last_bbox['x'], self.last_bbox['y'], 
            self.last_bbox['width'], self.last_bbox['height']
        )
        
        # æ‰©å¤§æœç´¢åŒºåŸŸ
        search_margin = 50
        search_x = max(0, last_x - search_margin)
        search_y = max(0, last_y - search_margin)
        search_w = min(frame.shape[1] - search_x, last_w + 2 * search_margin)
        search_h = min(frame.shape[0] - search_y, last_h + 2 * search_margin)
        
        # åœ¨æœç´¢åŒºåŸŸå†…æ£€æµ‹äººç‰©
        search_roi = frame[search_y:search_y+search_h, search_x:search_x+search_w]
        if search_roi.size > 0:
            person_bbox = self.detect_person(search_roi)
            if person_bbox:
                # è°ƒæ•´åæ ‡åˆ°åŸå›¾åæ ‡ç³»
                person_bbox['x'] += search_x
                person_bbox['y'] += search_y
                self.last_bbox = person_bbox
                self.tracked_positions.append(person_bbox)
                return person_bbox
        
        # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ä¸Šä¸€å¸§çš„ä½ç½®
        return self.last_bbox

# --- Feature 1: ä½¿ç”¨ FFmpeg çš„é«˜æ•ˆç‰‡æ®µæå– ---
def extract_segment(input_path: str, start_str: str, end_str: str):
    """
    ä½¿ç”¨ FFmpeg ä» input_path ä¸­æ ¹æ® start_str å’Œ end_str æå–è§†é¢‘ç‰‡æ®µã€‚
    è¿™ç§æ–¹æ³•æ¯” MoviePy å¿«å¾ˆå¤šï¼ŒCPU ä½¿ç”¨ç‡ä¹Ÿä½å¾ˆå¤šã€‚
    """
    try:
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not input_path or not os.path.exists(input_path):
            raise ValueError("è¯·å…ˆä¸Šä¼ è§†é¢‘æ–‡ä»¶")
        
        # è§£ææ—¶é—´
        start = time_to_seconds(start_str)
        end = time_to_seconds(end_str)
        
        if end <= start:
            raise ValueError("ç»“æŸæ—¶é—´å¿…é¡»å¤§äºå¼€å§‹æ—¶é—´")
        
        # æ£€æŸ¥è§†é¢‘æ—¶é•¿
        video_duration = get_video_duration(input_path)
        if video_duration > 0 and end > video_duration:
            raise ValueError(f"ç»“æŸæ—¶é—´ ({end_str}) è¶…è¿‡äº†è§†é¢‘æ€»æ—¶é•¿ ({video_duration:.1f} ç§’)")
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
        tmp_dir = tempfile.gettempdir()
        out_path = os.path.join(tmp_dir, f"segment_ffmpeg_{int(start*100)}_{int(end*100)}.mp4")
        
        # è½¬æ¢ä¸º FFmpeg æ—¶é—´æ ¼å¼
        start_time = seconds_to_ffmpeg_time(start)
        duration = end - start
        
        # ä½¿ç”¨ FFmpeg æå–ç‰‡æ®µ - ä½¿ç”¨ç²¾ç¡®åˆ‡å‰²æ¨¡å¼
        cmd_precise = [
            'ffmpeg', '-i', input_path,
            '-ss', start_time,
            '-t', str(duration),
            '-c:v', 'libx264',  # é‡æ–°ç¼–ç è§†é¢‘ä»¥ç¡®ä¿ç²¾ç¡®åˆ‡å‰²
            '-c:a', 'aac',      # é‡æ–°ç¼–ç éŸ³é¢‘
            '-preset', 'ultrafast',  # æœ€å¿«ç¼–ç é¢„è®¾
            '-crf', '23',       # ä¿æŒè‰¯å¥½è´¨é‡
            '-avoid_negative_ts', 'make_zero',
            '-fflags', '+genpts',  # ç”Ÿæˆæ–°çš„æ—¶é—´æˆ³
            '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            out_path
        ]
        
        print(f"æ‰§è¡Œç²¾ç¡®åˆ‡å‰² FFmpeg å‘½ä»¤: {' '.join(cmd_precise)}")
        
        # æ‰§è¡Œ FFmpeg å‘½ä»¤
        result = subprocess.run(cmd_precise, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"FFmpeg é”™è¯¯è¾“å‡º: {result.stderr}")
            raise ValueError(f"FFmpeg å¤„ç†å¤±è´¥: {result.stderr}")
        else:
            print("ç²¾ç¡®åˆ‡å‰²æˆåŠŸï¼")
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(out_path):
            raise ValueError("è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ")
        
        print(f"è§†é¢‘ç‰‡æ®µæå–æˆåŠŸ: {out_path}")
        return out_path, "", out_path  # è¿”å›è§†é¢‘è·¯å¾„ã€ç©ºé”™è¯¯æ¶ˆæ¯å’ŒçŠ¶æ€
        
    except Exception as e:
        error_msg = f"æå–è§†é¢‘ç‰‡æ®µæ—¶å‡ºé”™: {str(e)}"
        print(error_msg)
        return None, error_msg, None  # è¿”å› Noneã€é”™è¯¯æ¶ˆæ¯å’ŒçŠ¶æ€

# --- Feature 2: æ™ºèƒ½è§†é¢‘è£åˆ‡å’Œäººç‰©è·Ÿè¸ª ---
def crop_video_with_tracking(input_path: str, aspect_ratio: str, crop_x: float, crop_y: float, crop_width: float, crop_height: float):
    """
    æ™ºèƒ½è£åˆ‡è§†é¢‘ï¼Œæ”¯æŒäººç‰©è·Ÿè¸ªå’ŒåŠ¨æ€è°ƒæ•´
    """
    try:
        if not input_path or not os.path.exists(input_path):
            raise ValueError("è¯·å…ˆé€‰æ‹©è§†é¢‘æ–‡ä»¶")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = get_video_info(input_path)
        original_width = video_info['width']
        original_height = video_info['height']
        
        # è®¡ç®—è£åˆ‡åŒºåŸŸ
        crop_x_pixels = int(crop_x * original_width)
        crop_y_pixels = int(crop_y * original_height)
        crop_w_pixels = int(crop_width * original_width)
        crop_h_pixels = int(crop_height * original_height)
        
        # ç¡®ä¿è£åˆ‡åŒºåŸŸä¸è¶…å‡ºè§†é¢‘è¾¹ç•Œ
        crop_x_pixels = max(0, min(crop_x_pixels, original_width - crop_w_pixels))
        crop_y_pixels = max(0, min(crop_y_pixels, original_height - crop_h_pixels))
        crop_w_pixels = min(crop_w_pixels, original_width - crop_x_pixels)
        crop_h_pixels = min(crop_h_pixels, original_height - crop_y_pixels)
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
        tmp_dir = tempfile.gettempdir()
        output_path = os.path.join(tmp_dir, f"cropped_{aspect_ratio}_{int(crop_x*100)}_{int(crop_y*100)}.mp4")
        
        # æ„å»º FFmpeg å‘½ä»¤
        cmd = [
            'ffmpeg', '-i', input_path,
            '-vf', f'crop={crop_w_pixels}:{crop_h_pixels}:{crop_x_pixels}:{crop_y_pixels}',
            '-c:v', 'libx264',
            '-c:a', 'aac',
            '-preset', 'ultrafast',
            '-crf', '23',
            '-y', output_path
        ]
        
        print(f"æ‰§è¡Œè£åˆ‡å‘½ä»¤: {' '.join(cmd)}")
        
        # æ‰§è¡Œè£åˆ‡
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"è£åˆ‡å¤±è´¥: {result.stderr}")
            raise ValueError(f"è§†é¢‘è£åˆ‡å¤±è´¥: {result.stderr}")
        
        # å¦‚æœéœ€è¦æ·»åŠ é»‘è¾¹å®ç°9:16æ ¼å¼
        if aspect_ratio == "9:16":
            final_output = os.path.join(tmp_dir, f"final_9x16_{int(crop_x*100)}_{int(crop_y*100)}.mp4")
            
            # è·å–è£åˆ‡åè§†é¢‘çš„å°ºå¯¸
            crop_info = get_video_info(output_path)
            crop_width = crop_info['width']
            crop_height = crop_info['height']
            
            # è®¡ç®—9:16çš„ç›®æ ‡é«˜åº¦
            target_height = int(crop_width * 16 / 9)
            padding = (target_height - crop_height) // 2
            
            # æ·»åŠ é»‘è¾¹
            pad_cmd = [
                'ffmpeg', '-i', output_path,
                '-vf', f'pad={crop_width}:{target_height}:0:{padding}:black',
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'ultrafast',
                '-crf', '23',
                '-y', final_output
            ]
            
            print(f"æ·»åŠ é»‘è¾¹å‘½ä»¤: {' '.join(pad_cmd)}")
            pad_result = subprocess.run(pad_cmd, capture_output=True, text=True)
            
            if pad_result.returncode == 0:
                os.remove(output_path)  # åˆ é™¤ä¸­é—´æ–‡ä»¶
                output_path = final_output
            else:
                print(f"æ·»åŠ é»‘è¾¹å¤±è´¥: {pad_result.stderr}")
        
        print(f"è§†é¢‘è£åˆ‡æˆåŠŸ: {output_path}")
        return output_path, ""
        
    except Exception as e:
        error_msg = f"è§†é¢‘è£åˆ‡æ—¶å‡ºé”™: {str(e)}"
        print(error_msg)
        return None, error_msg

# --- Feature 3: äººç‰©è·Ÿè¸ªè£åˆ‡ ---
def crop_with_person_tracking(input_path: str, aspect_ratio: str, crop_x: float, crop_y: float, crop_width: float, crop_height: float):
    """
    ä½¿ç”¨äººç‰©è·Ÿè¸ªè¿›è¡Œæ™ºèƒ½è£åˆ‡ - çœŸæ­£è·Ÿè¸ªäººç‰©ç§»åŠ¨
    """
    try:
        if not input_path or not os.path.exists(input_path):
            raise ValueError("è¯·å…ˆé€‰æ‹©è§†é¢‘æ–‡ä»¶")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = get_video_info(input_path)
        original_width = video_info['width']
        original_height = video_info['height']
        
        # è®¡ç®—åˆå§‹è£åˆ‡æ¡†å°ºå¯¸
        crop_w_pixels = int(crop_width * original_width)
        crop_h_pixels = int(crop_height * original_height)
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
        tmp_dir = tempfile.gettempdir()
        output_path = os.path.join(tmp_dir, f"tracked_{aspect_ratio}.mp4")
        
        # æ‰“å¼€è§†é¢‘
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            raise ValueError("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
        
        # è·å–è§†é¢‘å±æ€§
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (crop_w_pixels, crop_h_pixels))
        
        # åˆå§‹åŒ–äººç‰©è·Ÿè¸ªå™¨
        tracker = PersonTracker()
        initialized = False
        
        print(f"å¼€å§‹äººç‰©è·Ÿè¸ªè£åˆ‡ï¼Œæ€»å¸§æ•°: {total_frames}")
        
        frame_count = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            if frame_count % 30 == 0:  # æ¯30å¸§æ‰“å°ä¸€æ¬¡è¿›åº¦
                print(f"å¤„ç†è¿›åº¦: {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%)")
            
            # åˆå§‹åŒ–è·Ÿè¸ªå™¨ï¼ˆåœ¨ç¬¬ä¸€å¸§æˆ–æ£€æµ‹åˆ°äººç‰©æ—¶ï¼‰
            if not initialized:
                # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„åŒºåŸŸä½œä¸ºåˆå§‹æ£€æµ‹åŒºåŸŸ
                initial_x = int(crop_x * original_width)
                initial_y = int(crop_y * original_height)
                
                # åœ¨åˆå§‹åŒºåŸŸé™„è¿‘æ£€æµ‹äººç‰©
                roi = frame[initial_y:initial_y+crop_h_pixels, initial_x:initial_x+crop_w_pixels]
                if roi.size > 0:
                    person_bbox = tracker.detect_person(roi)
                    if person_bbox:
                        # è°ƒæ•´åæ ‡åˆ°åŸå›¾åæ ‡ç³»
                        person_bbox['x'] += initial_x
                        person_bbox['y'] += initial_y
                        if tracker.initialize_tracker(frame, person_bbox):
                            initialized = True
                            print(f"äººç‰©è·Ÿè¸ªå™¨åˆå§‹åŒ–æˆåŠŸï¼Œå¸§ {frame_count}")
            
            # è·Ÿè¸ªäººç‰©
            if initialized:
                tracked_bbox = tracker.track_person(frame)
                if tracked_bbox:
                    # è®¡ç®—è£åˆ‡åŒºåŸŸï¼Œä»¥äººç‰©ä¸ºä¸­å¿ƒ
                    person_center_x = tracked_bbox['center_x']
                    person_center_y = tracked_bbox['center_y']
                    
                    # è®¡ç®—è£åˆ‡æ¡†ä½ç½®ï¼Œç¡®ä¿äººç‰©åœ¨ä¸­å¿ƒ
                    crop_x_pixels = max(0, min(person_center_x - crop_w_pixels // 2, original_width - crop_w_pixels))
                    crop_y_pixels = max(0, min(person_center_y - crop_h_pixels // 2, original_height - crop_h_pixels))
                else:
                    # è·Ÿè¸ªå¤±è´¥ï¼Œä½¿ç”¨ä¸Šä¸€å¸§çš„ä½ç½®æˆ–é»˜è®¤ä½ç½®
                    crop_x_pixels = int(crop_x * original_width)
                    crop_y_pixels = int(crop_y * original_height)
            else:
                # æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ä½ç½®
                crop_x_pixels = int(crop_x * original_width)
                crop_y_pixels = int(crop_y * original_height)
            
            # ç¡®ä¿è£åˆ‡åŒºåŸŸåœ¨è§†é¢‘èŒƒå›´å†…
            crop_x_pixels = max(0, min(crop_x_pixels, original_width - crop_w_pixels))
            crop_y_pixels = max(0, min(crop_y_pixels, original_height - crop_h_pixels))
            
            # è£åˆ‡å¸§
            cropped_frame = frame[crop_y_pixels:crop_y_pixels+crop_h_pixels, 
                                crop_x_pixels:crop_x_pixels+crop_w_pixels]
            
            # å†™å…¥è¾“å‡ºè§†é¢‘
            out.write(cropped_frame)
        
        # é‡Šæ”¾èµ„æº
        cap.release()
        out.release()
        
        # ä½¿ç”¨ FFmpeg é‡æ–°ç¼–ç ä»¥ç¡®ä¿å…¼å®¹æ€§
        final_output = os.path.join(tmp_dir, f"final_tracked_{aspect_ratio}.mp4")
        cmd = [
            'ffmpeg', '-i', output_path,
            '-c:v', 'libx264',
            '-c:a', 'aac',
            '-preset', 'ultrafast',
            '-crf', '23',
            '-y', final_output
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            os.remove(output_path)  # åˆ é™¤ä¸­é—´æ–‡ä»¶
            output_path = final_output
        
        print(f"äººç‰©è·Ÿè¸ªè£åˆ‡æˆåŠŸ: {output_path}")
        return output_path, ""
        
    except Exception as e:
        error_msg = f"äººç‰©è·Ÿè¸ªè£åˆ‡æ—¶å‡ºé”™: {str(e)}"
        print(error_msg)
        return None, error_msg

# --- è¾…åŠ©å‡½æ•° ---
def update_crop_preview(video_path, aspect_ratio, center_x, center_y, scale):
    """æ›´æ–°è£åˆ‡é¢„è§ˆå›¾åƒ"""
    if not video_path or not os.path.exists(video_path):
        return None
    
    try:
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = get_video_info(video_path)
        crop_box = calculate_crop_box(video_info['width'], video_info['height'], aspect_ratio, center_x, center_y, scale)
        
        # åˆ›å»ºé¢„è§ˆå›¾åƒ
        preview_path = create_crop_preview_image(video_path, aspect_ratio, 
                                               crop_box['x'], crop_box['y'], 
                                               crop_box['width'], crop_box['height'])
        return preview_path
    except Exception as e:
        print(f"æ›´æ–°é¢„è§ˆå¤±è´¥: {e}")
        return None

def get_crop_parameters(video_path, aspect_ratio, center_x, center_y, scale):
    """è·å–è£åˆ‡å‚æ•°"""
    if not video_path or not os.path.exists(video_path):
        return 0.1, 0.1, 0.8, 0.8
    
    try:
        video_info = get_video_info(video_path)
        crop_box = calculate_crop_box(video_info['width'], video_info['height'], aspect_ratio, center_x, center_y, scale)
        return crop_box['x'], crop_box['y'], crop_box['width'], crop_box['height']
    except Exception as e:
        print(f"è·å–è£åˆ‡å‚æ•°å¤±è´¥: {e}")
        return 0.1, 0.1, 0.8, 0.8

def select_video_source(extracted_video, direct_video):
    """é€‰æ‹©è§†é¢‘æºï¼šä¼˜å…ˆä½¿ç”¨ç›´æ¥ä¸Šä¼ çš„è§†é¢‘ï¼Œå…¶æ¬¡ä½¿ç”¨æå–çš„è§†é¢‘"""
    if direct_video and os.path.exists(direct_video):
        return direct_video
    elif extracted_video and os.path.exists(extracted_video):
        return extracted_video
    else:
        return None

def download_video_segment(video_path):
    """ä¸‹è½½è§†é¢‘ç‰‡æ®µ"""
    if video_path and os.path.exists(video_path):
        return gr.File.update(value=video_path, visible=True)
    else:
        return gr.File.update(value=None, visible=False)

def download_subtitle_file(subtitle_path):
    """ä¸‹è½½å­—å¹•æ–‡ä»¶"""
    if subtitle_path and os.path.exists(subtitle_path):
        return gr.File.update(value=subtitle_path, visible=True)
    else:
        return gr.File.update(value=None, visible=False)

def update_video_display(extracted_video):
    """æ›´æ–°è§†é¢‘æ˜¾ç¤ºï¼šå¦‚æœæœ‰æå–çš„è§†é¢‘åˆ™æ˜¾ç¤ºï¼Œå¦åˆ™æ˜¾ç¤ºä¸Šä¼ æŒ‰é’®"""
    if extracted_video and os.path.exists(extracted_video):
        return extracted_video, False  # æ˜¾ç¤ºè§†é¢‘ï¼Œéšè—ä¸Šä¼ æŒ‰é’®
    else:
        return None, True  # ä¸æ˜¾ç¤ºè§†é¢‘ï¼Œæ˜¾ç¤ºä¸Šä¼ æŒ‰é’®

# --- å­—å¹•ç”ŸæˆåŠŸèƒ½ ---
class SubtitleGenerator:
    def __init__(self):
        self.model = None
        # self.translator = Translator()
    
    def load_model(self, model_size="base"):
        """åŠ è½½Whisperæ¨¡å‹"""
        try:
            if self.model is None:
                print(f"æ­£åœ¨åŠ è½½Whisperæ¨¡å‹: {model_size}")
                # è®¾ç½®SSLéªŒè¯ä¸ºFalseæ¥è§£å†³è¯ä¹¦é—®é¢˜
                import ssl
                ssl._create_default_https_context = ssl._create_unverified_context
                self.model = whisper.load_model(model_size)
                print("Whisperæ¨¡å‹åŠ è½½å®Œæˆ")
            return True
        except Exception as e:
            print(f"åŠ è½½Whisperæ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def extract_audio(self, video_path):
        """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
        try:
            audio_path = video_path.replace('.mp4', '_audio.wav')
            cmd = [
                'ffmpeg', '-i', video_path,
                '-vn',  # ä¸åŒ…å«è§†é¢‘
                '-acodec', 'pcm_s16le',  # éŸ³é¢‘ç¼–ç 
                '-ar', '16000',  # é‡‡æ ·ç‡
                '-ac', '1',  # å•å£°é“
                '-y', audio_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                return audio_path
            else:
                raise Exception(f"éŸ³é¢‘æå–å¤±è´¥: {result.stderr}")
        except Exception as e:
            print(f"éŸ³é¢‘æå–é”™è¯¯: {e}")
            return None
    
    def transcribe_audio(self, audio_path):
        """ä½¿ç”¨Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        try:
            if not self.load_model():
                return None
            
            print("å¼€å§‹è¯­éŸ³è¯†åˆ«...")
            result = self.model.transcribe(audio_path)
            print("è¯­éŸ³è¯†åˆ«å®Œæˆ")
            return result
        except Exception as e:
            print(f"è¯­éŸ³è¯†åˆ«é”™è¯¯: {e}")
            return None
    
    def translate_text(self, text, target_lang='zh'):
        """ç¿»è¯‘æ–‡æœ¬"""
        try:
            if not text or text.strip() == "":
                return ""
            
            # æš‚æ—¶è¿”å›åŸæ–‡ï¼Œåç»­å¯ä»¥é›†æˆå…¶ä»–ç¿»è¯‘æœåŠ¡
            # translation = self.translator.translate(text, dest=target_lang)
            # return translation.text
            return f"[ä¸­æ–‡ç¿»è¯‘] {text}"  # ä¸´æ—¶å ä½ç¬¦
        except Exception as e:
            print(f"ç¿»è¯‘é”™è¯¯: {e}")
            return text  # ç¿»è¯‘å¤±è´¥æ—¶è¿”å›åŸæ–‡
    
    def format_subtitles(self, segments, translate=True):
        """æ ¼å¼åŒ–å­—å¹•"""
        subtitles = []
        for segment in segments:
            start_time = segment['start']
            end_time = segment['end']
            text = segment['text'].strip()
            
            # æ ¼å¼åŒ–æ—¶é—´
            start_str = f"{int(start_time//60):02d}:{start_time%60:05.2f}"
            end_str = f"{int(end_time//60):02d}:{end_time%60:05.2f}"
            
            subtitle_entry = {
                'start': start_time,
                'end': end_time,
                'start_str': start_str,
                'end_str': end_str,
                'en': text
            }
            
            if translate:
                subtitle_entry['zh'] = self.translate_text(text)
            
            subtitles.append(subtitle_entry)
        
        return subtitles
    
    def generate_srt(self, subtitles):
        """ç”ŸæˆSRTæ ¼å¼å­—å¹•"""
        srt_content = ""
        for i, subtitle in enumerate(subtitles, 1):
            srt_content += f"{i}\n"
            srt_content += f"{subtitle['start_str']} --> {subtitle['end_str']}\n"
            srt_content += f"{subtitle['en']}\n"
            if 'zh' in subtitle:
                srt_content += f"{subtitle['zh']}\n"
            srt_content += "\n"
        
        return srt_content
    
    def generate_ass_subtitles(self, subtitles):
        """ç”ŸæˆASSæ ¼å¼å­—å¹•æ–‡ä»¶ï¼Œæ”¯æŒæ ·å¼è®¾ç½®"""
        ass_content = """[Script Info]
Title: Generated Subtitles
ScriptType: v4.00+
WrapStyle: 1
ScaledBorderAndShadow: yes
YCbCr Matrix: TV.601

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,24,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
        
        for subtitle in subtitles:
            start_time = self.seconds_to_ass_time(subtitle['start'])
            end_time = self.seconds_to_ass_time(subtitle['end'])
            
            # è‹±æ–‡å­—å¹•
            en_text = subtitle['en'].replace('\n', '\\N')
            ass_content += f"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{en_text}\n"
            
            # ä¸­æ–‡å­—å¹•
            if 'zh' in subtitle:
                zh_text = subtitle['zh'].replace('\n', '\\N')
                ass_content += f"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{zh_text}\n"
        
        return ass_content
    
    def seconds_to_ass_time(self, seconds):
        """å°†ç§’æ•°è½¬æ¢ä¸ºASSæ—¶é—´æ ¼å¼ (H:MM:SS.cc)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = seconds % 60
        centiseconds = int((secs % 1) * 100)
        secs = int(secs)
        return f"{hours}:{minutes:02d}:{secs:02d}.{centiseconds:02d}"
    
    def embed_subtitles_to_video(self, video_path, subtitles, output_path=None):
        """å°†å­—å¹•åµŒå…¥åˆ°è§†é¢‘ä¸­"""
        try:
            if output_path is None:
                output_path = video_path.replace('.mp4', '_with_subtitles.mp4')
            
            # ç”ŸæˆASSå­—å¹•æ–‡ä»¶
            ass_content = self.generate_ass_subtitles(subtitles)
            ass_path = video_path.replace('.mp4', '_subtitles.ass')
            
            with open(ass_path, 'w', encoding='utf-8') as f:
                f.write(ass_content)
            
            # ä½¿ç”¨FFmpegå°†å­—å¹•åµŒå…¥è§†é¢‘
            cmd = [
                'ffmpeg', '-i', video_path,
                '-vf', f'ass={ass_path}',
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'ultrafast',
                '-crf', '23',
                '-y', output_path
            ]
            
            print(f"æ‰§è¡Œå­—å¹•åµŒå…¥å‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            # æ¸…ç†ä¸´æ—¶ASSæ–‡ä»¶
            if os.path.exists(ass_path):
                os.remove(ass_path)
            
            if result.returncode == 0:
                print(f"å­—å¹•åµŒå…¥æˆåŠŸ: {output_path}")
                return output_path
            else:
                print(f"å­—å¹•åµŒå…¥å¤±è´¥: {result.stderr}")
                return None
                
        except Exception as e:
            print(f"å­—å¹•åµŒå…¥é”™è¯¯: {e}")
            return None

def generate_subtitles(video_path, model_size="base", translate=True, embed_subtitles=False):
    """ç”Ÿæˆè§†é¢‘å­—å¹•çš„ä¸»å‡½æ•°"""
    try:
        if not video_path or not os.path.exists(video_path):
            return None, "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨"
        
        print(f"å¼€å§‹ä¸ºè§†é¢‘ç”Ÿæˆå­—å¹•: {video_path}")
        
        # åˆå§‹åŒ–å­—å¹•ç”Ÿæˆå™¨
        generator = SubtitleGenerator()
        
        # æå–éŸ³é¢‘
        print("æ­£åœ¨æå–éŸ³é¢‘...")
        audio_path = generator.extract_audio(video_path)
        if not audio_path:
            return None, "éŸ³é¢‘æå–å¤±è´¥"
        
        # è¯­éŸ³è¯†åˆ«
        result = generator.transcribe_audio(audio_path)
        if not result:
            return None, "è¯­éŸ³è¯†åˆ«å¤±è´¥"
        
        # æ ¼å¼åŒ–å­—å¹•
        print("æ­£åœ¨æ ¼å¼åŒ–å­—å¹•...")
        subtitles = generator.format_subtitles(result['segments'], translate)
        
        # ç”ŸæˆSRTæ–‡ä»¶
        srt_content = generator.generate_srt(subtitles)
        
        # ä¿å­˜SRTæ–‡ä»¶
        srt_path = video_path.replace('.mp4', '_subtitles.srt')
        with open(srt_path, 'w', encoding='utf-8') as f:
            f.write(srt_content)
        
        # å¦‚æœéœ€è¦åµŒå…¥å­—å¹•åˆ°è§†é¢‘ä¸­
        if embed_subtitles:
            print("æ­£åœ¨å°†å­—å¹•åµŒå…¥åˆ°è§†é¢‘ä¸­...")
            output_video_path = generator.embed_subtitles_to_video(video_path, subtitles)
            if output_video_path:
                # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                if os.path.exists(audio_path):
                    os.remove(audio_path)
                
                print(f"å­—å¹•åµŒå…¥å®Œæˆ: {output_video_path}")
                return output_video_path, f"å­—å¹•ç”Ÿæˆå¹¶åµŒå…¥æˆåŠŸï¼å…±ç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•"
            else:
                # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                if os.path.exists(audio_path):
                    os.remove(audio_path)
                return srt_path, f"å­—å¹•ç”ŸæˆæˆåŠŸï¼Œä½†åµŒå…¥å¤±è´¥ï¼å…±ç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•"
        
        # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        if os.path.exists(audio_path):
            os.remove(audio_path)
        
        print(f"å­—å¹•ç”Ÿæˆå®Œæˆ: {srt_path}")
        return srt_path, f"å­—å¹•ç”ŸæˆæˆåŠŸï¼å…±ç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•"
        
    except Exception as e:
        error_msg = f"å­—å¹•ç”Ÿæˆå¤±è´¥: {str(e)}"
        print(error_msg)
        return None, error_msg

def generate_subtitles_for_ui(video_path, model_size="base", translate=True, embed_subtitles=False):
    """ä¸ºUIç•Œé¢ç”Ÿæˆå­—å¹•çš„å‡½æ•°ï¼Œè¿”å›å­—å¹•å†…å®¹ã€çŠ¶æ€ä¿¡æ¯å’Œæ–‡ä»¶è·¯å¾„"""
    try:
        if not video_path or not os.path.exists(video_path):
            return "", "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨", None
        
        print(f"å¼€å§‹ä¸ºè§†é¢‘ç”Ÿæˆå­—å¹•: {video_path}")
        
        # åˆå§‹åŒ–å­—å¹•ç”Ÿæˆå™¨
        generator = SubtitleGenerator()
        
        # æå–éŸ³é¢‘
        print("æ­£åœ¨æå–éŸ³é¢‘...")
        audio_path = generator.extract_audio(video_path)
        if not audio_path:
            return "", "éŸ³é¢‘æå–å¤±è´¥", None
        
        # è¯­éŸ³è¯†åˆ«
        result = generator.transcribe_audio(audio_path)
        if not result:
            return "", "è¯­éŸ³è¯†åˆ«å¤±è´¥", None
        
        # æ ¼å¼åŒ–å­—å¹•
        print("æ­£åœ¨æ ¼å¼åŒ–å­—å¹•...")
        subtitles = generator.format_subtitles(result['segments'], translate)
        
        # ç”ŸæˆSRTå†…å®¹ç”¨äºæ˜¾ç¤º
        srt_content = generator.generate_srt(subtitles)
        
        # å¦‚æœéœ€è¦åµŒå…¥å­—å¹•åˆ°è§†é¢‘ä¸­
        if embed_subtitles:
            print("æ­£åœ¨å°†å­—å¹•åµŒå…¥åˆ°è§†é¢‘ä¸­...")
            output_video_path = generator.embed_subtitles_to_video(video_path, subtitles)
            if output_video_path:
                # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                if os.path.exists(audio_path):
                    os.remove(audio_path)
                
                print(f"å­—å¹•åµŒå…¥å®Œæˆ: {output_video_path}")
                return srt_content, f"å­—å¹•ç”Ÿæˆå¹¶åµŒå…¥æˆåŠŸï¼å…±ç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•ã€‚è¾“å‡ºè§†é¢‘ï¼š{os.path.basename(output_video_path)}", output_video_path
            else:
                # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                if os.path.exists(audio_path):
                    os.remove(audio_path)
                return srt_content, f"å­—å¹•ç”ŸæˆæˆåŠŸï¼Œä½†åµŒå…¥å¤±è´¥ï¼å…±ç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•", None
        
        # ä¿å­˜SRTæ–‡ä»¶
        srt_path = video_path.replace('.mp4', '_subtitles.srt')
        with open(srt_path, 'w', encoding='utf-8') as f:
            f.write(srt_content)
        
        # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        if os.path.exists(audio_path):
            os.remove(audio_path)
        
        print(f"å­—å¹•ç”Ÿæˆå®Œæˆ: {srt_path}")
        return srt_content, f"å­—å¹•ç”ŸæˆæˆåŠŸï¼å…±ç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•ã€‚æ–‡ä»¶ï¼š{os.path.basename(srt_path)}", srt_path
        
    except Exception as e:
        error_msg = f"å­—å¹•ç”Ÿæˆå¤±è´¥: {str(e)}"
        print(error_msg)
        return "", error_msg, None

# --- Gradio ç•Œé¢ & ç»‘å®š ---
with gr.Blocks(title="æ™ºèƒ½è§†é¢‘å‰ªè¾‘å·¥å…·") as demo:
    gr.Markdown("## ğŸš€ æ™ºèƒ½è§†é¢‘å‰ªè¾‘å·¥å…· â€” æ”¯æŒäººç‰©è·Ÿè¸ªå’Œå­—å¹•ç”Ÿæˆ")
    gr.Markdown("**åŠŸèƒ½ï¼š** è§†é¢‘ç‰‡æ®µæå– + æ™ºèƒ½è£åˆ‡ + äººç‰©è·Ÿè¸ª + å­—å¹•ç”Ÿæˆ")
    
    # å­˜å‚¨æå–çš„è§†é¢‘è·¯å¾„å’Œå­—å¹•æ–‡ä»¶è·¯å¾„
    extracted_video = gr.State()
    subtitle_file_path = gr.State()
    
    with gr.Tabs():
        # ç¬¬ä¸€ä¸ªæ ‡ç­¾é¡µï¼šè§†é¢‘ç‰‡æ®µæå–
        with gr.TabItem("ğŸ¬ è§†é¢‘ç‰‡æ®µæå–"):
            with gr.Row():
                with gr.Column():
                    video_input = gr.Video(label="ä¸Šä¼ è§†é¢‘ (<=3GB)")
                    
                    # æ—¶é—´é€‰æ‹©åŒºåŸŸ
                    with gr.Group():
                        gr.Markdown("### â° æ—¶é—´é€‰æ‹©")
                        with gr.Row():
                            start_time = gr.Textbox(label="å¼€å§‹æ—¶é—´ (MM:SS æˆ– HH:MM:SS)", placeholder="ä¾‹å¦‚: 1:50")
                            end_time = gr.Textbox(label="ç»“æŸæ—¶é—´ (MM:SS æˆ– HH:MM:SS)", placeholder="ä¾‹å¦‚: 4:00")
                        
                        # æ—¶é—´è½´é€‰æ‹©æç¤º
                        gr.Markdown("**ğŸ’¡ æç¤ºï¼š** ä¹Ÿå¯ä»¥åœ¨ä¸‹æ–¹è§†é¢‘é¢„è§ˆä¸­ç‚¹å‡»æ—¶é—´è½´æ¥è®¾ç½®å¼€å§‹å’Œç»“æŸæ—¶é—´")
                    
                    extract_btn = gr.Button("ğŸš€ å¿«é€Ÿæå–ç‰‡æ®µ", variant="primary")
                
                with gr.Column():
                    # è§†é¢‘é¢„è§ˆåŒºåŸŸ
                    with gr.Group():
                        gr.Markdown("### ğŸ“¹ è§†é¢‘é¢„è§ˆ")
                        preview = gr.Video(label="é¢„è§ˆç‰‡æ®µ", interactive=True)
                        
                        # ä¸‹è½½æŒ‰é’®
                        download_btn = gr.Button("â¬‡ï¸ ä¸‹è½½è§†é¢‘ç‰‡æ®µ", variant="secondary", visible=False)
                    
                    error_msg = gr.Textbox(label="çŠ¶æ€ä¿¡æ¯", interactive=False, visible=True)
                    info_text = gr.Markdown("""
                    **ä½¿ç”¨è¯´æ˜ï¼š**
                    1. ä¸Šä¼ è§†é¢‘æ–‡ä»¶
                    2. é€‰æ‹©æ—¶é—´èŒƒå›´ï¼š
                       - æ‰‹åŠ¨è¾“å…¥å¼€å§‹å’Œç»“æŸæ—¶é—´
                       - æˆ–åœ¨è§†é¢‘é¢„è§ˆä¸­ç‚¹å‡»æ—¶é—´è½´
                    3. ç‚¹å‡»"å¿«é€Ÿæå–ç‰‡æ®µ"
                    4. ç­‰å¾…å¤„ç†å®Œæˆ
                    5. ç‚¹å‡»"ä¸‹è½½è§†é¢‘ç‰‡æ®µ"ä¿å­˜æ–‡ä»¶
                    
                    **æ—¶é—´æ ¼å¼æ”¯æŒï¼š**
                    - `MM:SS` (å¦‚: 1:50, 4:00)
                    - `HH:MM:SS` (å¦‚: 1:30:45)
                    """)
            
            extract_btn.click(fn=extract_segment,
                             inputs=[video_input, start_time, end_time],
                             outputs=[preview, error_msg, extracted_video])
            
            # å½“æå–æˆåŠŸæ—¶æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
            extract_btn.click(
                fn=lambda x: True if x else False,
                inputs=[extracted_video],
                outputs=[download_btn]
            )
            
            # ä¸‹è½½æŒ‰é’®åŠŸèƒ½
            download_btn.click(
                fn=download_video_segment,
                inputs=[extracted_video],
                outputs=[download_btn, error_msg]
            )
        
        # ç¬¬äºŒä¸ªæ ‡ç­¾é¡µï¼šæ™ºèƒ½è£åˆ‡
        with gr.TabItem("âœ‚ï¸ æ™ºèƒ½è§†é¢‘è£åˆ‡"):
            with gr.Row():
                with gr.Column():
                    # è§†é¢‘è¾“å…¥åŒºåŸŸ
                    with gr.Group():
                        gr.Markdown("### ğŸ“¹ è§†é¢‘è¾“å…¥")
                        # ç»Ÿä¸€çš„è§†é¢‘é¢„è§ˆåŒºåŸŸ
                        crop_video_display = gr.Video(label="è§†é¢‘é¢„è§ˆ", interactive=True)
                        
                        # æ¡ä»¶æ˜¾ç¤ºçš„ä¸Šä¼ æŒ‰é’®
                        upload_btn = gr.Button("ğŸ“ ä¸Šä¼ è§†é¢‘æ–‡ä»¶", variant="secondary", visible=True)
                    
                    # è£åˆ‡è®¾ç½®
                    with gr.Group():
                        gr.Markdown("### âš™ï¸ è£åˆ‡è®¾ç½®")
                        aspect_ratio = gr.Radio(
                            choices=["3:4", "1:1"],
                            label="é€‰æ‹©å›ºå®šæ¯”ä¾‹æ¡†",
                            value="3:4"
                        )
                    
                    # è£åˆ‡æ¡†æ§åˆ¶
                    with gr.Row():
                        center_x = gr.Slider(0, 1, 0.5, label="æ¡†ä¸­å¿ƒ X ä½ç½®", step=0.01)
                        center_y = gr.Slider(0, 1, 0.5, label="æ¡†ä¸­å¿ƒ Y ä½ç½®", step=0.01)
                    
                    scale = gr.Slider(0.1, 1, 0.8, label="æ¡†ç¼©æ”¾å¤§å°", step=0.01)
                    
                    with gr.Row():
                        update_preview_btn = gr.Button("ğŸ”„ æ›´æ–°é¢„è§ˆ", variant="secondary")
                        manual_crop_btn = gr.Button("âœ‚ï¸ æ‰‹åŠ¨è£åˆ‡", variant="primary")
                        auto_track_btn = gr.Button("ğŸ¯ äººç‰©è·Ÿè¸ªè£åˆ‡", variant="secondary")
                
                with gr.Column():
                    # è£åˆ‡é¢„è§ˆå›¾åƒ
                    crop_preview_image = gr.Image(label="è£åˆ‡æ¡†é¢„è§ˆ", type="filepath")
                    crop_preview = gr.Video(label="è£åˆ‡ç»“æœé¢„è§ˆ")
                    crop_error_msg = gr.Textbox(label="è£åˆ‡çŠ¶æ€", interactive=False, visible=True)
                    crop_info = gr.Markdown("""
                    **è£åˆ‡åŠŸèƒ½è¯´æ˜ï¼š**
                    
                    **è§†é¢‘è¾“å…¥æ–¹å¼ï¼š**
                    - **æ–¹å¼ä¸€**ï¼šåœ¨"è§†é¢‘ç‰‡æ®µæå–"æ ‡ç­¾é¡µæå–è§†é¢‘ç‰‡æ®µï¼Œè‡ªåŠ¨ä¼ é€’åˆ°æ­¤é¡µé¢
                    - **æ–¹å¼äºŒ**ï¼šç›´æ¥åœ¨æ­¤é¡µé¢ä¸Šä¼ è§†é¢‘æ–‡ä»¶
                    
                    **ä½¿ç”¨æ­¥éª¤ï¼š**
                    1. é€‰æ‹©è§†é¢‘è¾“å…¥æ–¹å¼ï¼š
                       - ä»ç¬¬ä¸€æ­¥æå–çš„è§†é¢‘ç‰‡æ®µä¼šè‡ªåŠ¨æ˜¾ç¤º
                       - æˆ–ç‚¹å‡»"ä¸Šä¼ è§†é¢‘æ–‡ä»¶"æŒ‰é’®ä¸Šä¼ æ–°è§†é¢‘
                    2. é€‰æ‹©å›ºå®šæ¯”ä¾‹æ¡† (3:4 æˆ– 1:1)
                    3. è°ƒæ•´æ¡†çš„ä½ç½®å’Œå¤§å°ï¼Œæ¡†ä½è¦è·Ÿè¸ªçš„äººç‰©
                    4. ç‚¹å‡»"æ›´æ–°é¢„è§ˆ"æŸ¥çœ‹è£åˆ‡æ¡†
                    5. é€‰æ‹©è£åˆ‡æ–¹å¼ï¼š
                       - **æ‰‹åŠ¨è£åˆ‡**ï¼šå›ºå®šä½ç½®è£åˆ‡
                       - **äººç‰©è·Ÿè¸ªè£åˆ‡**ï¼šåŠ¨æ€è·Ÿè¸ªäººç‰©ç§»åŠ¨
                    
                    **è£åˆ‡æ¡†æ“ä½œï¼š**
                    - æ‹–åŠ¨æ»‘å—è°ƒæ•´è£åˆ‡æ¡†ä½ç½®å’Œå¤§å°
                    - è£åˆ‡æ¡†ä¼šä¿æŒé€‰æ‹©çš„æ¯”ä¾‹
                    - ç¡®ä¿æ¡†å†…åŒ…å«è¦è·Ÿè¸ªçš„äººç‰©
                    
                    **äººç‰©è·Ÿè¸ªåŠŸèƒ½ï¼š**
                    - è‡ªåŠ¨æ£€æµ‹æ¡†å†…çš„äººç‰©
                    - å®æ—¶è·Ÿè¸ªäººç‰©ç§»åŠ¨
                    - è£åˆ‡æ¡†ä¼šè·Ÿéšäººç‰©ç§»åŠ¨
                    - ä¿æŒäººç‰©åœ¨ç”»é¢ä¸­å¿ƒ
                    
                    **3:4 æ¯”ä¾‹ï¼š** é€‚åˆç«–å±çŸ­è§†é¢‘
                    **1:1 æ¯”ä¾‹ï¼š** é€‚åˆæ–¹å½¢è§†é¢‘
                    
                    **ğŸ’¡ æç¤ºï¼š** è§†é¢‘é¢„è§ˆåŒºåŸŸä¼šæ™ºèƒ½æ˜¾ç¤ºå½“å‰å¯ç”¨çš„è§†é¢‘
                    """)
            
            # å½“æå–çš„è§†é¢‘æ›´æ–°æ—¶ï¼Œæ›´æ–°è£åˆ‡ç•Œé¢çš„è§†é¢‘æ˜¾ç¤ºå’Œä¸Šä¼ æŒ‰é’®çŠ¶æ€
            extracted_video.change(
                fn=update_video_display,
                inputs=[extracted_video],
                outputs=[crop_video_display, upload_btn]
            )
            
            # å½“ä¸Šä¼ æŒ‰é’®è¢«ç‚¹å‡»æ—¶ï¼Œå…è®¸ç”¨æˆ·ä¸Šä¼ è§†é¢‘
            upload_btn.click(
                fn=lambda x: x,
                inputs=[upload_btn],
                outputs=[crop_video_display]
            )
            
            # å½“æ¯”ä¾‹æ”¹å˜æ—¶ï¼Œæ›´æ–°é¢„è§ˆ
            aspect_ratio.change(
                fn=lambda video, ratio, cx, cy, s: update_crop_preview(video, ratio, cx, cy, s),
                inputs=[crop_video_display, aspect_ratio, center_x, center_y, scale],
                outputs=[crop_preview_image]
            )
            
            # å½“ä½ç½®æˆ–ç¼©æ”¾æ”¹å˜æ—¶ï¼Œæ›´æ–°é¢„è§ˆ
            center_x.change(
                fn=lambda video, ratio, cx, cy, s: update_crop_preview(video, ratio, cx, cy, s),
                inputs=[crop_video_display, aspect_ratio, center_x, center_y, scale],
                outputs=[crop_preview_image]
            )
            
            center_y.change(
                fn=lambda video, ratio, cx, cy, s: update_crop_preview(video, ratio, cx, cy, s),
                inputs=[crop_video_display, aspect_ratio, center_x, center_y, scale],
                outputs=[crop_preview_image]
            )
            
            scale.change(
                fn=lambda video, ratio, cx, cy, s: update_crop_preview(video, ratio, cx, cy, s),
                inputs=[crop_video_display, aspect_ratio, center_x, center_y, scale],
                outputs=[crop_preview_image]
            )
            
            # æ›´æ–°é¢„è§ˆæŒ‰é’®
            update_preview_btn.click(
                fn=lambda video, ratio, cx, cy, s: update_crop_preview(video, ratio, cx, cy, s),
                inputs=[crop_video_display, aspect_ratio, center_x, center_y, scale],
                outputs=[crop_preview_image]
            )
            
            # æ‰‹åŠ¨è£åˆ‡æŒ‰é’®
            manual_crop_btn.click(
                fn=lambda video, ratio, cx, cy, s: crop_video_with_tracking(
                    video, ratio, *get_crop_parameters(video, ratio, cx, cy, s)
                ),
                inputs=[crop_video_display, aspect_ratio, center_x, center_y, scale],
                outputs=[crop_preview, crop_error_msg]
            )
            
            # äººç‰©è·Ÿè¸ªè£åˆ‡æŒ‰é’®
            auto_track_btn.click(
                fn=lambda video, ratio, cx, cy, s: crop_with_person_tracking(
                    video, ratio, *get_crop_parameters(video, ratio, cx, cy, s)
                ),
                inputs=[crop_video_display, aspect_ratio, center_x, center_y, scale],
                outputs=[crop_preview, crop_error_msg]
            )
        
        # ç¬¬ä¸‰ä¸ªæ ‡ç­¾é¡µï¼šå­—å¹•ç”Ÿæˆ
        with gr.TabItem("ğŸ“ å­—å¹•ç”Ÿæˆ"):
            with gr.Row():
                with gr.Column():
                    # è§†é¢‘è¾“å…¥åŒºåŸŸ
                    with gr.Group():
                        gr.Markdown("### ğŸ“¹ è§†é¢‘è¾“å…¥")
                        subtitle_video_input = gr.Video(label="ä¸Šä¼ è§†é¢‘æ–‡ä»¶", interactive=True)
                    
                    # å­—å¹•è®¾ç½®
                    with gr.Group():
                        gr.Markdown("### âš™ï¸ å­—å¹•è®¾ç½®")
                        model_size = gr.Radio(
                            choices=["tiny", "base", "small", "medium", "large"],
                            label="Whisperæ¨¡å‹å¤§å°",
                            value="base",
                            info="æ¨¡å‹è¶Šå¤§ï¼Œè¯†åˆ«è¶Šå‡†ç¡®ï¼Œä½†å¤„ç†æ—¶é—´è¶Šé•¿"
                        )
                        
                        translate_subtitles = gr.Checkbox(
                            label="ç¿»è¯‘ä¸ºä¸­æ–‡",
                            value=True,
                            info="è‡ªåŠ¨å°†è‹±æ–‡å­—å¹•ç¿»è¯‘ä¸ºä¸­æ–‡"
                        )
                        
                        embed_subtitles = gr.Checkbox(
                            label="åµŒå…¥å­—å¹•åˆ°è§†é¢‘",
                            value=False,
                            info="å°†ç”Ÿæˆçš„å­—å¹•ç›´æ¥åµŒå…¥åˆ°è§†é¢‘ä¸­ï¼ˆæ¨èï¼‰"
                        )
                    
                    generate_subtitle_btn = gr.Button("ğŸ¯ ç”Ÿæˆå­—å¹•", variant="primary")
                
                with gr.Column():
                    # å­—å¹•é¢„è§ˆå’Œä¸‹è½½
                    with gr.Group():
                        gr.Markdown("### ğŸ“„ å­—å¹•é¢„è§ˆ")
                        subtitle_preview = gr.Textbox(
                            label="å­—å¹•å†…å®¹é¢„è§ˆ",
                            lines=15,
                            interactive=False,
                            placeholder="å­—å¹•ç”Ÿæˆåå°†åœ¨æ­¤æ˜¾ç¤º..."
                        )
                        
                        download_subtitle_btn = gr.Button("â¬‡ï¸ ä¸‹è½½å­—å¹•æ–‡ä»¶", variant="secondary", visible=False)
                    
                    subtitle_error_msg = gr.Textbox(label="å¤„ç†çŠ¶æ€", interactive=False, visible=True)
                    subtitle_info = gr.Markdown("""
                    **å­—å¹•ç”ŸæˆåŠŸèƒ½è¯´æ˜ï¼š**
                    
                    **åŠŸèƒ½ç‰¹ç‚¹ï¼š**
                    - ğŸ¤ **è¯­éŸ³è¯†åˆ«**ï¼šä½¿ç”¨OpenAI Whisperè¿›è¡Œé«˜ç²¾åº¦è¯­éŸ³è¯†åˆ«
                    - ğŸŒ **å¤šè¯­è¨€æ”¯æŒ**ï¼šæ”¯æŒè‹±æ–‡ç­‰å¤šç§è¯­è¨€çš„è¯­éŸ³è¯†åˆ«
                    - ğŸ”„ **è‡ªåŠ¨ç¿»è¯‘**ï¼šå°†è‹±æ–‡å­—å¹•è‡ªåŠ¨ç¿»è¯‘ä¸ºä¸­æ–‡
                    - ğŸ“ **SRTæ ¼å¼**ï¼šç”Ÿæˆæ ‡å‡†SRTå­—å¹•æ–‡ä»¶
                    
                    **ä½¿ç”¨æ­¥éª¤ï¼š**
                    1. ä¸Šä¼ åŒ…å«è¯­éŸ³çš„è§†é¢‘æ–‡ä»¶
                    2. é€‰æ‹©Whisperæ¨¡å‹å¤§å°ï¼ˆæ¨èbaseæˆ–smallï¼‰
                    3. é€‰æ‹©æ˜¯å¦éœ€è¦ä¸­æ–‡ç¿»è¯‘
                    4. ç‚¹å‡»"ç”Ÿæˆå­—å¹•"
                    5. ç­‰å¾…å¤„ç†å®Œæˆ
                    6. ä¸‹è½½å­—å¹•æ–‡ä»¶
                    
                    **æ¨¡å‹å¤§å°è¯´æ˜ï¼š**
                    - **tiny**: æœ€å¿«ï¼Œé€‚åˆæµ‹è¯•
                    - **base**: å¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®æ€§ï¼ˆæ¨èï¼‰
                    - **small**: æ›´å‡†ç¡®ï¼Œå¤„ç†æ—¶é—´è¾ƒé•¿
                    - **medium**: é«˜å‡†ç¡®æ€§ï¼Œå¤„ç†æ—¶é—´é•¿
                    - **large**: æœ€é«˜å‡†ç¡®æ€§ï¼Œå¤„ç†æ—¶é—´æœ€é•¿
                    
                    **ğŸ’¡ æç¤ºï¼š** é¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½Whisperæ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…
                    """)
            
            # å­—å¹•ç”ŸæˆæŒ‰é’®äº‹ä»¶
            generate_subtitle_btn.click(
                fn=lambda video, model, translate, embed: generate_subtitles_for_ui(video, model, translate, embed),
                inputs=[subtitle_video_input, model_size, translate_subtitles, embed_subtitles],
                outputs=[subtitle_preview, subtitle_error_msg, subtitle_file_path]
            )
            
            # å½“å­—å¹•ç”ŸæˆæˆåŠŸæ—¶æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
            generate_subtitle_btn.click(
                fn=lambda x: True if x else False,
                inputs=[subtitle_file_path],
                outputs=[download_subtitle_btn]
            )
            
            # ä¸‹è½½å­—å¹•æŒ‰é’®äº‹ä»¶
            download_subtitle_btn.click(
                fn=download_subtitle_file,
                inputs=[subtitle_file_path],
                outputs=[download_subtitle_btn]
            )

if __name__ == "__main__":
    demo.launch(share=False)
